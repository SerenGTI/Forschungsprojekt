%!TEX root=../main.tex

\section{Discussion}
There are two main cases that should be regarded in a comparison of the frameworks. 
One, the case of individual calculations on a graph, i.e. for each calculation, the graph has to be loaded. 
Further, the algorithm can change frequently, requiring the framework to be relatively fast on different algorithms.
This is called the \emph{research} case.
For research, frameworks with overall small execution times and small overhead are preferred.
Case two on the other hand is the case of a running system, that performs multiple calculations on a single graph, without the need of reloading graph data with every calculation. This is the \emph{production} case.
In production, frameworks with short calculation times should be preferred because the overhead time is only spent once on startup and amortizes quickly.

Orthogonal to this, the graph size and topology of the system are deciding factors. Large graphs often require a distributed cluster, because the graph is simply too large to fit in the RAM of just one machine. We observed this for example with Giraph on multiple graphs.
Giraph requires a lot more memory than any of the other frameworks and ran out of memory on multiple occasions. 
Thus it should only really be considered on distributed setups.
Furthermore, some environments require a distributed framework setup regardless of any other factors.

%## production
On production systems, we expect it to be possible to determine what configuration is best before putting the system in service.
But not only the absolute runtime of each computation has to be taken into account. Production systems have to be very reliable because downtime often directly correlates to financial loss.
This is often a reason for choosing a distributed system. Many nodes together are less prone to failure of the entire system.
Thus, there is an argument to be made for systems like Hadoop.
It automatically handles node failures, whith a node failure not immediately resulting in loss of data or faulty computation results.
This is especially important on very large clusters, that can not easily be monitored by humans.
Further, a user defining an application does not need to know the topology of the system that runs the application later on.
Hadoop transparently splits the input data and distributes work among the worker nodes.
Additionally, Giraph using hadoop shows a bias towards larger graphs, we observed an improvement in performance over single-node Giraph, when increasing the size of the input graph.
This shows the hadoop infrastructure to be working well with large graphs being exactly what the distributed system should be used for. 
Only a system like hadoop can reasonably be used on such large clusters.
Any of the other framewors will just result in large administration overhead due to node failures or other problems of distributed systems in general.
Furthermore, the calculation times of Giraph proved to be very fast in comparison to the other distributed frameworks, with Giraph often being one of the fastest framework in computation time.
Very short calculation times along with automatic handling of the computation cluster make Giraph using Hadoop a good choice for production systems.
Pregel is a similar, fault-tolerant and scalable system but it is contrary to Giraph closed-source.

But not only distributed production systems are possible, of course. 
For small graphs, i.e. those that are not too large for single node RAM, a single-node setup is usually faster than the same framework on a distributed cluster. 
We have shown that the distributed cluster of the same framework becomes faster than the equivalent single-node setup only on large graphs.
We have found around 2B edges, or roughly the size of the twitter graph to be a size at which Ligra and Giraph become faster on the distributed setup compared to single-node.
If required, horizontal scaling can for example be used to provide fault-tolerance of the entire system.

If only the calculation time is important, there are multiple options with the deciding factors being the graph size and the application.
For algorithms that perform a traversal through the graph, with a concentrated and relativly small amount of active vertices, our results for SSSP and BFS are most relevant.
Here Galois is fastest on very small graphs (i.e. flickr), but is quickly overtaken by other frameworks.
In the case of SSSP those are Gemini and Polymer and on BFS they are Ligra and again Gemini. While Gemini is not the fastest on either BFS or SSSP, it is still the safest bet on other algorithms. That is because Polymer is fast on SSSP but slowest on BFS and in turn Ligra is fastest on BFS but one of the slowest frameworks on SSSP. Gemini is second fastest on SSSP and BFS on the larger graphs.
Also, it might be important to consider the implementation style of a custom application for either of the frameworks.
Applications similar to BFS and SSSP are expected to perform better with a push style implementation. 
This is because they are algorithms with only few active vertices or where the affected push areas are not overlapping. 
Hence, only little synchronization is needed that could be impacting performance negatively.

If the problem is however of a nature, where many vertices are active, thus many vertices, widely spread across the graph perform some kind of calculation, our results for PR are to be considered.
Because PageRank has many active vertices it is expected to perform much better with pull implementations, because less synchronization is needed in that case. This should be kept in mind when developing custom applications.
Galois is the fastest framework on PR in either calculation time or execution time, regardless of push or pull version. Though for custom applications, one style might be significantly faster than the other.

A good guideline is pull-style on single-node systems with PR-like applications and push-style for SSSP and BFS, especially on distributed systems.
The synchronization time on distributed systems is not as severely impacting performance because communication over the network is needed anyways. Communication over the network is usually slower than local synchonization.
Our data backs this up, we observed single-node PageRank to be fastest with Galois Pull, while the push based algorithms were fastest on the distributed systems.

%## research
For single-node research systems, a overall good execution time on \emph{any} application is necessary. 
Here we recommend Galois as the fastest executing single-node framework overall.
It provides excellent performance, being orders of magnitude faster than the competing frameworks. And when it is possible to use hugepages, further improvements in performance can be expected. We frequently observed Galois with hugepages to be around 2 times faster compared to Galois without hugepages.
Also, we have shown that most algorithms are able to utilize many threads in favour of much smaller calculation times. Graph-traversal algorithms like BFS or SSSP shown here are examples for such algorithms.
Supplying a large thread pool for Galois is most likely improving performance on those algorithms.
However, especially when using push-style algorithms, a large thread count is most likely not going to significantly improve performance over single threaded results. 
The reason for this is the synchronization required for push applications. This is true not only for single-node Galois but any framework.

Distributed research systems do not have the same requirements as production systems. For example node failures are not as problematic, because the system is most likely reconfigured frequently anyways.
Hence, Giraph as the go-to distributed system so far is not applicable here. Hadoop handling all the parallelization and fault-tolerance in the background is a nice-to-have in a production system. But in research, one might not be willing to pay the price of increased execution times over other frameworks.
A framework that is fast in many algorithms is required. 
Galois is the fastest framework on SSSP and BFS, by a margin of around one order of magnitude to Gemini. 
On PR however, Galois is only second fastest. It is about one order of magnitude behind Gemini on three of the seven graphs.
Hence, the choice of framework really depends on the kind of work expected to run on the system. For graph-traversal or similar applications, Galois outperforms Gemini. For research with PR-like applications, Gemini would be a wise choice.

