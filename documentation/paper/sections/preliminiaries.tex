%!TEX root=../main.tex

\section{Preliminaries}
This section briefly explains the concepts and applications necessary, but not directly related to our work.
Initialy graphs and paths are defined, followed by explanations for various graph analysis applications.
Afterwards a few models for compution on graphs or large data sets in general are explained as well as hugepages.

\subsection{Graphs and Paths}
An \emph{unweighted graph} is the pair $G=(V,E)$ where the \emph{vertex set} is $V\subseteq\mathbb N$ and the $E$ is the \emph{edge set}.
The edge set describes a number of connections or relations between two vertices. Depending on these relations, a graph can be directed or undirected. For a \emph{directed graph} the edge set is defined as
\begin{equation*}
  E\subseteq\{(x,y)\,|\, x,y\in V, x\neq y\}
\end{equation*}
and in the \emph{undirected} case, the direction is no longer relevant. Thus, in an undirected graph for each $(x,y)\in E: (x,y)=(y,x)$ holds.
The size of a graph is defined as the number of edges $|E|$ \cite{newman2010networks}.
Independently of the graph being directed or not, a graph can be \emph{weighted}. In this case a function $w:E\rightarrow \mathbb R$ is introduced, that maps an edge to a numerical value, further describing the relation.

A \emph{Path} from starting vertex $s$ to target vertex $t$ is a sequence of vertices
\begin{equation*}
	P=(x_1,x_2,\ldots,x_n)\in V^n
\end{equation*}
with the condition $(x_i,x_{i+1})\in E$ for each $i\in\{1,\ldots,n-1\}$ and $x_1=s, x_n=t$.
Thus we call a target $t$ \emph{reachable} from $s$ if a Path from $s$ to $t$ exists.

\subsection{Single-Source Shortest-Paths}
Single-Source Shortest-Paths (SSSP) describes the problem of finding the shortest path from a starting vertex to every other vertex in the input graph.
Input to the problem is a weighted graph $G=(V,E)$ and a start vertex $s\in V$. Output is the shortest possible distance from $s$ to each vertex in $V$.
The distance is defined as the sum of edge weights $w_i$ on a path from $s$ to the target.
In the case of a unweighted graph, the distance is often described in \emph{hops}, i.e. the number of edges on a path.
The most common sequential implementations are Dijkstra's algorithm or BellmanFord \cite{Polymer, Ligra, pregel}.

\subsection{Breadth-First Search}
Breadth-first search (BFS) is a search problem on a graph.
It requires an unweighted graph and a start vertex as input.
The output is a set of vertices that are reachable from the start vertex.
In some special cases, a target vertex is also given. In the case of a target being given, the output is true if a path from start to target exists and otherwise false.
It is called Breadth-First search because the algorithm searches in a path length-based way. First all paths of length one i.e. all neighbors of the start vertex are checked before checking paths of length two and so on.

\subsection{PageRank}
\emph{PageRank} (PR) is a link analysis algorithm that weighs the vertices of a graph, measuring the vertices relative importance within the graph \cite{pagerank}.
The algorithm was invented by Sergey Brin and Larry Page, the founders of Google. To this date, Google Search uses a modified version of PageRank to rank web pages in their search engine results.
It is also used as a centrality metric.

The output of PageRank is a percentage for each vertex. This percentage, called the PageRank of the vertex, is the probability of arriving at this vertex when starting at a random vertex and then following random edges.
With a small probability, the damping factor, a jump is made to a completely random vertex instead of following an edge.
The PageRank can be calculated by iterating
\begin{equation*}
	\operatorname{PR}(v_i) = \frac{1 - d}{|V|} + d \sum_{v_j \in \operatorname{N^-}(v_i)} \frac{\operatorname{PR}(v_j)}{\operatorname{deg^+}(v_j)}
\end{equation*}
for all edges $v_i \in V$.
$d$ is the damping factor, $\operatorname{deg^+}(v)$ is the number of outgoing edges the vertex $v$ has and $\operatorname{N^-}(v)$ denotes the set of vertices that have edges to vertex $v$.

The analogy is that the graph represents website pages of the Word Wide Web, that are hyperlinked between one another.
PageRank simulates a random surfer who is following links.

An optimization to the traditional PageRank implementation is called \emph{Delta-PageRank}.
The PageRank score of a vertex is only updated if the relative change of the PageRank is larger than some user-defined delta.
In the next iteration only neighbors of vertices whose PageRank has changed need to be recalculated, thus computation time can be saved.

\subsection{Push and Pull Variants}
Many parallel graph algorithms, including the three we consider here, are implemented by iterating over vertices \cite{tao}.
To each of the vertices an operator is applied.
This operator reads and writes the labels of the active vertex and of the vertices in the direct surrounding, also called neighbourhood, of the active vertex.
It's also possible to iterate over edges, but in the following, whithout loss of generality, we will use the term active vertex.

Often this operator can be implemented in two different ways, called \emph{push style} or \emph{pull style}.
A \emph{push-style} operator reads the label of the active vertex and updates the label of its neighborhood.
These operators are more efficient, if there are only a few active vertices at the same time, or the neighborhoods do not overlap, which can not be avoided in general.
In contrast the \emph{pull-style} operator reads all values of its neighborhood and updates the value of the active vertex.
\emph{Pull-style} operators need less synchronization in parallel implementations, because unlike \emph{push style} there is only one write and many read operations.
Thus locks can be avoided.
So these operators are more efficient, if there are many active vertices at the same time.

\subsection{Bulk-Synchronous Parallel Model}
\label{sec:bsp}
The Bulk-Synchronous Parallel (BSP) model is a computation model developed by Leslie Valiant \cite{bsp}. It is commonly used in computation environments with large amounts of synchronous computation.
This model describes components, a communication network between those components and a method of synchronization.
The components are capable of performing computations and transactions on \emph{local} memory. Pairs of components can only communicate using messages, thus remote memory access is also only possible in this way.
The Messages have a user-defined form and should be as small as possible to keep the network traffic low. The \emph{Congest model} is a closely related model and furthermore describes the messages. There, the message length has to be logarithmic in the graph size \cite{congestModel}.

Synchronization is realized through barriers for some or all processes.
BSP algorithms are performed in a series of global supersteps. These consist of three steps, beginning with the processors performing local computations concurrently.
This step can overlap with the second, the communication between components. Processes can exchange information to access remote data.
Lastly, processes reaching a barrier wait until all other processes have reached the same barrier.

One of the most famous graph processing systems, Pregel \cite{pregel} is based on the BSP computation model. We include Giraph, an open-source variant of Pregel in our evaluation.
Pregel, Giraph and many frameworks similar to those were built to process large graphs reliably (offering fault tolerance) on large MapReduce infrastructures \cite{Giraph,graphx,powergraph}.

\subsection{MapReduce}
The MapReduce model is a computation infrastructure developed by Google to reliably handle large data sets on distributed clusters \cite{mapreduce}.

A user specifies just the two functions Map and Reduce.
The system hides the details of parallelization: fault-tolerance, data distribution and load balancing away from the application logic.
All of these features are automatically provided.
Execution is performed in three phases:
\begin{enumerate}
	\item Map phase: The input data is distributed between a set of Map processes, the Map functionality is specified by the user. Ideally all Map processes run in parallel so the map processes need to be independent. Results from this phase are written into (multiple) intermediate storage points.
	\item Shuffle phase: The results are grouped according to a key provided by the Map algorithm. Each set of results is then handed to one system for the next phase.
	\item Reduce phase: Every set of intermediate results is input to exactly one reduce process. The Reduce functionality is again specified by the user and ideally runs in parallel.
\end{enumerate}
Giraph \cite{Giraph} is an example of a system using this framework.

\subsection{Hugepages}
Most systems in use today use a so-called virtual memory management \cite{virtual_memory}.
It is implemented in the kernel and represents an abstraction between the memory devices of a machine and the individual programs.
Each program gets its own virtual leading address space.
This simplifies the implementation of applications considerably and also increases security, since each program can only access its own virtual address space.
The address areas are organized in so called pages, which in most cases are 4 KiB in size.
In the Translation lookaside buffer (TBL) the most recent translations of virtual memory to physical memory are cached.

Translating from the virtual to the physical address space significantly reduces the performance of today's data processing systems, since the size of the RAM grows much faster than the size of the TBL \cite{hugepages, superpages}.
To counteract this problem, hugepages were developed, which are usually several mibibytes in size.
This minimizes the CPU time needed for table lookups, because there are fewer TBL misses.
This speedup is especially noticeable in very memory intensive applications, like graph processing systems.

